{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EN3160 Assignment 3 on Neural Networks\n",
    "\n",
    "Instructed by Dr. Ranga Rodrigo\n",
    "\n",
    "Done by Jayakumar W.S. (210236P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This assignment is focused on implementing neural networks for image classification. This is done by using:\n",
    "1. Our own neural network implementation\n",
    "2. An implementation of LeNet-5\n",
    "3. An implementation of ResNet-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose ([ transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5) , (0.5, 0.5, 0.5))])\n",
    "batch_size = 32\n",
    "trainset = torchvision.datasets.CIFAR10(root= './data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root= './data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device begin used : {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our own architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Din = 3*32*32 # Input size (flattened CIFAR=10 image size)\n",
    "K = 10 # Output size (number of classes in CIFAR=10)\n",
    "std = 1e-5\n",
    "# Initialize weights and biases\n",
    "w = torch.randn(Din, K, device=device, dtype=torch.float, requires_grad=True) * std\n",
    "b = torch.randn(K, device=device, dtype=torch.float, requires_grad=True)\n",
    "# Hyperparameters\n",
    "iterations = 20\n",
    "lr = 2e-6 # Learning rate\n",
    "lr_decay = 0.9 # Learning rate decay\n",
    "reg = 0 # Regularization\n",
    "loss_history = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(iterations):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        Ntr = inputs.shape[0]  # Batch size\n",
    "        x_train = inputs.view(Ntr, -1).to(device)  # Flatten input to (Ntr, Din)\n",
    "        y_train_onehot = nn.functional.one_hot(labels, K).float().to(device)  # Convert labels to one-hot\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = x_train.mm(w) + b  # Output layer activation\n",
    "\n",
    "        # Loss calculation (Mean Squared Error with regularization)\n",
    "        loss = (1/Ntr) * torch.sum((y_pred - y_train_onehot) ** 2) + reg * torch.sum(w ** 2)\n",
    "        loss_history.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        dy_pred = (2.0 / Ntr) * (y_pred - y_train_onehot)\n",
    "        dw = x_train.t().mm(dy_pred) + reg * w\n",
    "        db = dy_pred.sum(dim=0)\n",
    "\n",
    "        # Parameter update\n",
    "        w = w - lr * dw\n",
    "        b = b - lr * db\n",
    "\n",
    "    print(f\"Epoch {t + 1} / {iterations}, Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "    # Learning rate decay\n",
    "    lr *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del w, b, x_train, y_train_onehot, y_pred, loss, dy_pred, dw, db\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation is not efficient and is only for educational purposes. For real-world applications, use PyTorch's built-in functions and classes. This fails\n",
    "# as memory usage increases with the number of iterations.\n",
    "\n",
    "Din = 3*32*32 # Input size (flattened CIFAR=10 image size)\n",
    "K = 10 # Output size (number of classes in CIFAR=10)\n",
    "std = 1e-5\n",
    "# Initialize weights and biases\n",
    "w1 = torch.randn(Din, 100, device=device, requires_grad=True)\n",
    "b1 = torch.zeros(100, device=device, requires_grad=True)\n",
    "w2 = torch.randn(100, K, device=device, requires_grad=True)\n",
    "b2 = torch.zeros(K, device=device, requires_grad=True)\n",
    "# Hyperparameters\n",
    "iterations = 20\n",
    "lr = 2e-6 # Learning rate\n",
    "lr_decay = 0.9 # Learning rate decay\n",
    "reg = 0 # Regularization\n",
    "loss_history = [ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(iterations) :\n",
    "    running_loss = 0.0\n",
    "    for i , data in enumerate(trainloader, 0) :\n",
    "        # Get inputs and labe l s\n",
    "        inputs , labels = data\n",
    "        Ntr = inputs.shape[0] # Batch size\n",
    "        x_train = inputs.view(Ntr, -1).to(device) # Flatten input to (Ntr, Din)\n",
    "        y_train_onehot = nn.functional.one_hot(labels, K).float().to(device) # Convert labe l s to one=hot # Forward pass\n",
    "        hidden = x_train.mm(w1) + b1\n",
    "        y_pred = hidden.mm(w2) + b2\n",
    "        # Loss calculation (Mean Squared Error with regularization)\n",
    "        loss = (1/Ntr) * torch.sum((y_pred - y_train_onehot) ** 2) + reg * (torch.sum(w1 ** 2) + torch.sum(w2 ** 2))\n",
    "        loss_history.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        # Backpropagation\n",
    "        dy_pred = (2.0 / Ntr) * (y_pred - y_train_onehot)\n",
    "        dhidden = dy_pred.mm(w2.t()) \n",
    "        dw2 = hidden.t().mm(dy_pred) + reg * w2\n",
    "        db2 = dy_pred.sum(dim=0)\n",
    "        dw1 = x_train.t().mm(dhidden) + reg * w1\n",
    "        db1 = dhidden.sum(dim=0)\n",
    "        # Parameter update\n",
    "        w2 = w2 - lr * dw2\n",
    "        b2 = b2 - lr * db2\n",
    "        w1 = w1 - lr * dw1\n",
    "        b1 = b1 - lr * db1\n",
    "    print(f\"Epoch {t+1} / {iterations} , Loss : {running_loss/len(trainloader)}\")\n",
    "    # Learning rat e decay\n",
    "    lr *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del w1, b1, w2, b2, x_train, y_train_onehot, y_pred, loss, dy_pred, dhidden, dw2, db2, dw1, db1\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, Din, H, Dout):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(Din, H)\n",
    "        self.linear2 = nn.Linear(H, Dout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(Din, 100, K).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(iterations):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        Ntr = inputs.shape[0]  # Batch size\n",
    "        x_train = inputs.view(Ntr, -1).to(device)  # Flatten input to (Ntr, Din)\n",
    "        y_train = labels.to(device)  # Convert labels to one-hot\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss_val = loss(y_pred, y_train)\n",
    "        loss_history.append(loss_val.item())\n",
    "        running_loss += loss_val.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {t + 1} / {iterations}, Loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "model.eval()\n",
    "with  torch.inference_mode():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        x_test, y_test = inputs.to(device), labels.to(device)\n",
    "        y_pred = model(x_test)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        accuracy += (predicted == y_test).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {accuracy / len(testset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "classes = tuple(str(i) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, input_size, input_channels, output_size):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        conv_output_size = ((input_size - 4) // 2 - 4) // 2\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * conv_output_size * conv_output_size, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.conv2(y)\n",
    "        y = y.view(y.size(0), -1)\n",
    "        y = self.classifier(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(input_size = 28, input_channels = 1, output_size = 10).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_history = [ ]\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10, Loss: 0.22979344264939428\n",
      "Epoch 2 / 10, Loss: 0.06832440779755512\n",
      "Epoch 3 / 10, Loss: 0.04808383764217918\n",
      "Epoch 4 / 10, Loss: 0.03904317057208003\n",
      "Epoch 5 / 10, Loss: 0.03111796266750122\n",
      "Epoch 6 / 10, Loss: 0.027499199597144617\n",
      "Epoch 7 / 10, Loss: 0.02319336009456941\n",
      "Epoch 8 / 10, Loss: 0.01949250753870971\n",
      "Epoch 9 / 10, Loss: 0.01712961347642146\n",
      "Epoch 10 / 10, Loss: 0.014968328931884146\n"
     ]
    }
   ],
   "source": [
    "for t in range(iterations):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        x_train, y_train = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss_val = loss(y_pred, y_train)\n",
    "        loss_history.append(loss_val.item())\n",
    "        running_loss += loss_val.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {t + 1} / {iterations}, Loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "model.eval()\n",
    "with  torch.inference_mode():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        x_test, y_test = inputs.to(device), labels.to(device)\n",
    "        y_pred = model(x_test)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        accuracy += (predicted == y_test).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {accuracy / len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, loss, optimizer, x_train, y_train, y_pred, loss_val\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights = 'IMAGENET1K_V1').to(device)\n",
    "data_folder = './data/hymenoptera_data'\n",
    "train_transforms = transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "trainset = torchvision.datasets.ImageFolder(root=f'{data_folder}/train', transform=train_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "testset = torchvision.datasets.ImageFolder(root=f'{data_folder}/val', transform=test_transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Trainable\n",
      "============================================================================================================================================\n",
      "ResNet                                   [32, 3, 224, 224]         [32, 1000]                --                        True\n",
      "├─Conv2d: 1-1                            [32, 3, 224, 224]         [32, 64, 112, 112]        9,408                     True\n",
      "├─BatchNorm2d: 1-2                       [32, 64, 112, 112]        [32, 64, 112, 112]        128                       True\n",
      "├─ReLU: 1-3                              [32, 64, 112, 112]        [32, 64, 112, 112]        --                        --\n",
      "├─MaxPool2d: 1-4                         [32, 64, 112, 112]        [32, 64, 56, 56]          --                        --\n",
      "├─Sequential: 1-5                        [32, 64, 56, 56]          [32, 64, 56, 56]          --                        True\n",
      "│    └─BasicBlock: 2-1                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        True\n",
      "│    │    └─Conv2d: 3-1                  [32, 64, 56, 56]          [32, 64, 56, 56]          36,864                    True\n",
      "│    │    └─BatchNorm2d: 3-2             [32, 64, 56, 56]          [32, 64, 56, 56]          128                       True\n",
      "│    │    └─ReLU: 3-3                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    │    └─Conv2d: 3-4                  [32, 64, 56, 56]          [32, 64, 56, 56]          36,864                    True\n",
      "│    │    └─BatchNorm2d: 3-5             [32, 64, 56, 56]          [32, 64, 56, 56]          128                       True\n",
      "│    │    └─ReLU: 3-6                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    └─BasicBlock: 2-2                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        True\n",
      "│    │    └─Conv2d: 3-7                  [32, 64, 56, 56]          [32, 64, 56, 56]          36,864                    True\n",
      "│    │    └─BatchNorm2d: 3-8             [32, 64, 56, 56]          [32, 64, 56, 56]          128                       True\n",
      "│    │    └─ReLU: 3-9                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    │    └─Conv2d: 3-10                 [32, 64, 56, 56]          [32, 64, 56, 56]          36,864                    True\n",
      "│    │    └─BatchNorm2d: 3-11            [32, 64, 56, 56]          [32, 64, 56, 56]          128                       True\n",
      "│    │    └─ReLU: 3-12                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "├─Sequential: 1-6                        [32, 64, 56, 56]          [32, 128, 28, 28]         --                        True\n",
      "│    └─BasicBlock: 2-3                   [32, 64, 56, 56]          [32, 128, 28, 28]         --                        True\n",
      "│    │    └─Conv2d: 3-13                 [32, 64, 56, 56]          [32, 128, 28, 28]         73,728                    True\n",
      "│    │    └─BatchNorm2d: 3-14            [32, 128, 28, 28]         [32, 128, 28, 28]         256                       True\n",
      "│    │    └─ReLU: 3-15                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    │    └─Conv2d: 3-16                 [32, 128, 28, 28]         [32, 128, 28, 28]         147,456                   True\n",
      "│    │    └─BatchNorm2d: 3-17            [32, 128, 28, 28]         [32, 128, 28, 28]         256                       True\n",
      "│    │    └─Sequential: 3-18             [32, 64, 56, 56]          [32, 128, 28, 28]         8,448                     True\n",
      "│    │    └─ReLU: 3-19                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    └─BasicBlock: 2-4                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        True\n",
      "│    │    └─Conv2d: 3-20                 [32, 128, 28, 28]         [32, 128, 28, 28]         147,456                   True\n",
      "│    │    └─BatchNorm2d: 3-21            [32, 128, 28, 28]         [32, 128, 28, 28]         256                       True\n",
      "│    │    └─ReLU: 3-22                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    │    └─Conv2d: 3-23                 [32, 128, 28, 28]         [32, 128, 28, 28]         147,456                   True\n",
      "│    │    └─BatchNorm2d: 3-24            [32, 128, 28, 28]         [32, 128, 28, 28]         256                       True\n",
      "│    │    └─ReLU: 3-25                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "├─Sequential: 1-7                        [32, 128, 28, 28]         [32, 256, 14, 14]         --                        True\n",
      "│    └─BasicBlock: 2-5                   [32, 128, 28, 28]         [32, 256, 14, 14]         --                        True\n",
      "│    │    └─Conv2d: 3-26                 [32, 128, 28, 28]         [32, 256, 14, 14]         294,912                   True\n",
      "│    │    └─BatchNorm2d: 3-27            [32, 256, 14, 14]         [32, 256, 14, 14]         512                       True\n",
      "│    │    └─ReLU: 3-28                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    │    └─Conv2d: 3-29                 [32, 256, 14, 14]         [32, 256, 14, 14]         589,824                   True\n",
      "│    │    └─BatchNorm2d: 3-30            [32, 256, 14, 14]         [32, 256, 14, 14]         512                       True\n",
      "│    │    └─Sequential: 3-31             [32, 128, 28, 28]         [32, 256, 14, 14]         33,280                    True\n",
      "│    │    └─ReLU: 3-32                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    └─BasicBlock: 2-6                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        True\n",
      "│    │    └─Conv2d: 3-33                 [32, 256, 14, 14]         [32, 256, 14, 14]         589,824                   True\n",
      "│    │    └─BatchNorm2d: 3-34            [32, 256, 14, 14]         [32, 256, 14, 14]         512                       True\n",
      "│    │    └─ReLU: 3-35                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    │    └─Conv2d: 3-36                 [32, 256, 14, 14]         [32, 256, 14, 14]         589,824                   True\n",
      "│    │    └─BatchNorm2d: 3-37            [32, 256, 14, 14]         [32, 256, 14, 14]         512                       True\n",
      "│    │    └─ReLU: 3-38                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "├─Sequential: 1-8                        [32, 256, 14, 14]         [32, 512, 7, 7]           --                        True\n",
      "│    └─BasicBlock: 2-7                   [32, 256, 14, 14]         [32, 512, 7, 7]           --                        True\n",
      "│    │    └─Conv2d: 3-39                 [32, 256, 14, 14]         [32, 512, 7, 7]           1,179,648                 True\n",
      "│    │    └─BatchNorm2d: 3-40            [32, 512, 7, 7]           [32, 512, 7, 7]           1,024                     True\n",
      "│    │    └─ReLU: 3-41                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    │    └─Conv2d: 3-42                 [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,296                 True\n",
      "│    │    └─BatchNorm2d: 3-43            [32, 512, 7, 7]           [32, 512, 7, 7]           1,024                     True\n",
      "│    │    └─Sequential: 3-44             [32, 256, 14, 14]         [32, 512, 7, 7]           132,096                   True\n",
      "│    │    └─ReLU: 3-45                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    └─BasicBlock: 2-8                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        True\n",
      "│    │    └─Conv2d: 3-46                 [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,296                 True\n",
      "│    │    └─BatchNorm2d: 3-47            [32, 512, 7, 7]           [32, 512, 7, 7]           1,024                     True\n",
      "│    │    └─ReLU: 3-48                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    │    └─Conv2d: 3-49                 [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,296                 True\n",
      "│    │    └─BatchNorm2d: 3-50            [32, 512, 7, 7]           [32, 512, 7, 7]           1,024                     True\n",
      "│    │    └─ReLU: 3-51                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [32, 512, 7, 7]           [32, 512, 1, 1]           --                        --\n",
      "├─Linear: 1-10                           [32, 512]                 [32, 1000]                513,000                   True\n",
      "============================================================================================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 58.05\n",
      "============================================================================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 1271.92\n",
      "Params size (MB): 46.76\n",
      "Estimated Total Size (MB): 1337.94\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(batch_size, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, len(classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Trainable\n",
      "============================================================================================================================================\n",
      "ResNet                                   [32, 3, 224, 224]         [32, 2]                   --                        True\n",
      "├─Conv2d: 1-1                            [32, 3, 224, 224]         [32, 64, 112, 112]        9,408                     True\n",
      "├─BatchNorm2d: 1-2                       [32, 64, 112, 112]        [32, 64, 112, 112]        128                       True\n",
      "├─ReLU: 1-3                              [32, 64, 112, 112]        [32, 64, 112, 112]        --                        --\n",
      "├─MaxPool2d: 1-4                         [32, 64, 112, 112]        [32, 64, 56, 56]          --                        --\n",
      "├─Sequential: 1-5                        [32, 64, 56, 56]          [32, 64, 56, 56]          --                        True\n",
      "│    └─BasicBlock: 2-1                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        True\n",
      "│    │    └─Conv2d: 3-1                  [32, 64, 56, 56]          [32, 64, 56, 56]          36,864                    True\n",
      "│    │    └─BatchNorm2d: 3-2             [32, 64, 56, 56]          [32, 64, 56, 56]          128                       True\n",
      "│    │    └─ReLU: 3-3                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    │    └─Conv2d: 3-4                  [32, 64, 56, 56]          [32, 64, 56, 56]          36,864                    True\n",
      "│    │    └─BatchNorm2d: 3-5             [32, 64, 56, 56]          [32, 64, 56, 56]          128                       True\n",
      "│    │    └─ReLU: 3-6                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    └─BasicBlock: 2-2                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        True\n",
      "│    │    └─Conv2d: 3-7                  [32, 64, 56, 56]          [32, 64, 56, 56]          36,864                    True\n",
      "│    │    └─BatchNorm2d: 3-8             [32, 64, 56, 56]          [32, 64, 56, 56]          128                       True\n",
      "│    │    └─ReLU: 3-9                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    │    └─Conv2d: 3-10                 [32, 64, 56, 56]          [32, 64, 56, 56]          36,864                    True\n",
      "│    │    └─BatchNorm2d: 3-11            [32, 64, 56, 56]          [32, 64, 56, 56]          128                       True\n",
      "│    │    └─ReLU: 3-12                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "├─Sequential: 1-6                        [32, 64, 56, 56]          [32, 128, 28, 28]         --                        True\n",
      "│    └─BasicBlock: 2-3                   [32, 64, 56, 56]          [32, 128, 28, 28]         --                        True\n",
      "│    │    └─Conv2d: 3-13                 [32, 64, 56, 56]          [32, 128, 28, 28]         73,728                    True\n",
      "│    │    └─BatchNorm2d: 3-14            [32, 128, 28, 28]         [32, 128, 28, 28]         256                       True\n",
      "│    │    └─ReLU: 3-15                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    │    └─Conv2d: 3-16                 [32, 128, 28, 28]         [32, 128, 28, 28]         147,456                   True\n",
      "│    │    └─BatchNorm2d: 3-17            [32, 128, 28, 28]         [32, 128, 28, 28]         256                       True\n",
      "│    │    └─Sequential: 3-18             [32, 64, 56, 56]          [32, 128, 28, 28]         8,448                     True\n",
      "│    │    └─ReLU: 3-19                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    └─BasicBlock: 2-4                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        True\n",
      "│    │    └─Conv2d: 3-20                 [32, 128, 28, 28]         [32, 128, 28, 28]         147,456                   True\n",
      "│    │    └─BatchNorm2d: 3-21            [32, 128, 28, 28]         [32, 128, 28, 28]         256                       True\n",
      "│    │    └─ReLU: 3-22                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    │    └─Conv2d: 3-23                 [32, 128, 28, 28]         [32, 128, 28, 28]         147,456                   True\n",
      "│    │    └─BatchNorm2d: 3-24            [32, 128, 28, 28]         [32, 128, 28, 28]         256                       True\n",
      "│    │    └─ReLU: 3-25                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "├─Sequential: 1-7                        [32, 128, 28, 28]         [32, 256, 14, 14]         --                        True\n",
      "│    └─BasicBlock: 2-5                   [32, 128, 28, 28]         [32, 256, 14, 14]         --                        True\n",
      "│    │    └─Conv2d: 3-26                 [32, 128, 28, 28]         [32, 256, 14, 14]         294,912                   True\n",
      "│    │    └─BatchNorm2d: 3-27            [32, 256, 14, 14]         [32, 256, 14, 14]         512                       True\n",
      "│    │    └─ReLU: 3-28                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    │    └─Conv2d: 3-29                 [32, 256, 14, 14]         [32, 256, 14, 14]         589,824                   True\n",
      "│    │    └─BatchNorm2d: 3-30            [32, 256, 14, 14]         [32, 256, 14, 14]         512                       True\n",
      "│    │    └─Sequential: 3-31             [32, 128, 28, 28]         [32, 256, 14, 14]         33,280                    True\n",
      "│    │    └─ReLU: 3-32                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    └─BasicBlock: 2-6                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        True\n",
      "│    │    └─Conv2d: 3-33                 [32, 256, 14, 14]         [32, 256, 14, 14]         589,824                   True\n",
      "│    │    └─BatchNorm2d: 3-34            [32, 256, 14, 14]         [32, 256, 14, 14]         512                       True\n",
      "│    │    └─ReLU: 3-35                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    │    └─Conv2d: 3-36                 [32, 256, 14, 14]         [32, 256, 14, 14]         589,824                   True\n",
      "│    │    └─BatchNorm2d: 3-37            [32, 256, 14, 14]         [32, 256, 14, 14]         512                       True\n",
      "│    │    └─ReLU: 3-38                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "├─Sequential: 1-8                        [32, 256, 14, 14]         [32, 512, 7, 7]           --                        True\n",
      "│    └─BasicBlock: 2-7                   [32, 256, 14, 14]         [32, 512, 7, 7]           --                        True\n",
      "│    │    └─Conv2d: 3-39                 [32, 256, 14, 14]         [32, 512, 7, 7]           1,179,648                 True\n",
      "│    │    └─BatchNorm2d: 3-40            [32, 512, 7, 7]           [32, 512, 7, 7]           1,024                     True\n",
      "│    │    └─ReLU: 3-41                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    │    └─Conv2d: 3-42                 [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,296                 True\n",
      "│    │    └─BatchNorm2d: 3-43            [32, 512, 7, 7]           [32, 512, 7, 7]           1,024                     True\n",
      "│    │    └─Sequential: 3-44             [32, 256, 14, 14]         [32, 512, 7, 7]           132,096                   True\n",
      "│    │    └─ReLU: 3-45                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    └─BasicBlock: 2-8                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        True\n",
      "│    │    └─Conv2d: 3-46                 [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,296                 True\n",
      "│    │    └─BatchNorm2d: 3-47            [32, 512, 7, 7]           [32, 512, 7, 7]           1,024                     True\n",
      "│    │    └─ReLU: 3-48                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    │    └─Conv2d: 3-49                 [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,296                 True\n",
      "│    │    └─BatchNorm2d: 3-50            [32, 512, 7, 7]           [32, 512, 7, 7]           1,024                     True\n",
      "│    │    └─ReLU: 3-51                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [32, 512, 7, 7]           [32, 512, 1, 1]           --                        --\n",
      "├─Linear: 1-10                           [32, 512]                 [32, 2]                   1,026                     True\n",
      "============================================================================================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 11,177,538\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 58.03\n",
      "============================================================================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 1271.66\n",
      "Params size (MB): 44.71\n",
      "Estimated Total Size (MB): 1335.64\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(batch_size, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_history = []\n",
    "iterations = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 15, Loss: 0.7344811707735062\n",
      "Epoch 2 / 15, Loss: 0.7005684748291969\n",
      "Epoch 3 / 15, Loss: 0.4183211587369442\n",
      "Epoch 4 / 15, Loss: 0.3508832957595587\n",
      "Epoch 5 / 15, Loss: 0.31578759104013443\n",
      "Epoch 6 / 15, Loss: 0.23475292138755322\n",
      "Epoch 7 / 15, Loss: 0.2736297268420458\n",
      "Epoch 8 / 15, Loss: 0.21533881919458508\n",
      "Epoch 9 / 15, Loss: 0.1913422178477049\n",
      "Epoch 10 / 15, Loss: 0.250522131100297\n",
      "Epoch 11 / 15, Loss: 0.2673525484278798\n",
      "Epoch 12 / 15, Loss: 0.23732879757881165\n",
      "Epoch 13 / 15, Loss: 0.20999886561185122\n",
      "Epoch 14 / 15, Loss: 0.1920069344341755\n",
      "Epoch 15 / 15, Loss: 0.2966100051999092\n"
     ]
    }
   ],
   "source": [
    "for t in range(iterations):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        x_train, y_train = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss_val = loss(y_pred, y_train)\n",
    "        loss_history.append(loss_val.item())\n",
    "        running_loss += loss_val.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {t + 1} / {iterations}, Loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.869281045751634\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "model.eval()\n",
    "with  torch.inference_mode():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        x_test, y_test = inputs.to(device), labels.to(device)\n",
    "        y_pred = model(x_test)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        accuracy += (predicted == y_test).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {accuracy / len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights = 'IMAGENET1K_V1').to(device)\n",
    "model.fc = nn.Linear(512, len(classes)).to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Trainable\n",
      "============================================================================================================================================\n",
      "ResNet                                   [32, 3, 224, 224]         [32, 2]                   --                        Partial\n",
      "├─Conv2d: 1-1                            [32, 3, 224, 224]         [32, 64, 112, 112]        (9,408)                   False\n",
      "├─BatchNorm2d: 1-2                       [32, 64, 112, 112]        [32, 64, 112, 112]        (128)                     False\n",
      "├─ReLU: 1-3                              [32, 64, 112, 112]        [32, 64, 112, 112]        --                        --\n",
      "├─MaxPool2d: 1-4                         [32, 64, 112, 112]        [32, 64, 56, 56]          --                        --\n",
      "├─Sequential: 1-5                        [32, 64, 56, 56]          [32, 64, 56, 56]          --                        False\n",
      "│    └─BasicBlock: 2-1                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        False\n",
      "│    │    └─Conv2d: 3-1                  [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n",
      "│    │    └─BatchNorm2d: 3-2             [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n",
      "│    │    └─ReLU: 3-3                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    │    └─Conv2d: 3-4                  [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n",
      "│    │    └─BatchNorm2d: 3-5             [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n",
      "│    │    └─ReLU: 3-6                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    └─BasicBlock: 2-2                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        False\n",
      "│    │    └─Conv2d: 3-7                  [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n",
      "│    │    └─BatchNorm2d: 3-8             [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n",
      "│    │    └─ReLU: 3-9                    [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "│    │    └─Conv2d: 3-10                 [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n",
      "│    │    └─BatchNorm2d: 3-11            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n",
      "│    │    └─ReLU: 3-12                   [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n",
      "├─Sequential: 1-6                        [32, 64, 56, 56]          [32, 128, 28, 28]         --                        False\n",
      "│    └─BasicBlock: 2-3                   [32, 64, 56, 56]          [32, 128, 28, 28]         --                        False\n",
      "│    │    └─Conv2d: 3-13                 [32, 64, 56, 56]          [32, 128, 28, 28]         (73,728)                  False\n",
      "│    │    └─BatchNorm2d: 3-14            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n",
      "│    │    └─ReLU: 3-15                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    │    └─Conv2d: 3-16                 [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n",
      "│    │    └─BatchNorm2d: 3-17            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n",
      "│    │    └─Sequential: 3-18             [32, 64, 56, 56]          [32, 128, 28, 28]         (8,448)                   False\n",
      "│    │    └─ReLU: 3-19                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    └─BasicBlock: 2-4                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        False\n",
      "│    │    └─Conv2d: 3-20                 [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n",
      "│    │    └─BatchNorm2d: 3-21            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n",
      "│    │    └─ReLU: 3-22                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "│    │    └─Conv2d: 3-23                 [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n",
      "│    │    └─BatchNorm2d: 3-24            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n",
      "│    │    └─ReLU: 3-25                   [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n",
      "├─Sequential: 1-7                        [32, 128, 28, 28]         [32, 256, 14, 14]         --                        False\n",
      "│    └─BasicBlock: 2-5                   [32, 128, 28, 28]         [32, 256, 14, 14]         --                        False\n",
      "│    │    └─Conv2d: 3-26                 [32, 128, 28, 28]         [32, 256, 14, 14]         (294,912)                 False\n",
      "│    │    └─BatchNorm2d: 3-27            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n",
      "│    │    └─ReLU: 3-28                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    │    └─Conv2d: 3-29                 [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n",
      "│    │    └─BatchNorm2d: 3-30            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n",
      "│    │    └─Sequential: 3-31             [32, 128, 28, 28]         [32, 256, 14, 14]         (33,280)                  False\n",
      "│    │    └─ReLU: 3-32                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    └─BasicBlock: 2-6                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        False\n",
      "│    │    └─Conv2d: 3-33                 [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n",
      "│    │    └─BatchNorm2d: 3-34            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n",
      "│    │    └─ReLU: 3-35                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "│    │    └─Conv2d: 3-36                 [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n",
      "│    │    └─BatchNorm2d: 3-37            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n",
      "│    │    └─ReLU: 3-38                   [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n",
      "├─Sequential: 1-8                        [32, 256, 14, 14]         [32, 512, 7, 7]           --                        False\n",
      "│    └─BasicBlock: 2-7                   [32, 256, 14, 14]         [32, 512, 7, 7]           --                        False\n",
      "│    │    └─Conv2d: 3-39                 [32, 256, 14, 14]         [32, 512, 7, 7]           (1,179,648)               False\n",
      "│    │    └─BatchNorm2d: 3-40            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n",
      "│    │    └─ReLU: 3-41                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    │    └─Conv2d: 3-42                 [32, 512, 7, 7]           [32, 512, 7, 7]           (2,359,296)               False\n",
      "│    │    └─BatchNorm2d: 3-43            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n",
      "│    │    └─Sequential: 3-44             [32, 256, 14, 14]         [32, 512, 7, 7]           (132,096)                 False\n",
      "│    │    └─ReLU: 3-45                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    └─BasicBlock: 2-8                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        False\n",
      "│    │    └─Conv2d: 3-46                 [32, 512, 7, 7]           [32, 512, 7, 7]           (2,359,296)               False\n",
      "│    │    └─BatchNorm2d: 3-47            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n",
      "│    │    └─ReLU: 3-48                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "│    │    └─Conv2d: 3-49                 [32, 512, 7, 7]           [32, 512, 7, 7]           (2,359,296)               False\n",
      "│    │    └─BatchNorm2d: 3-50            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n",
      "│    │    └─ReLU: 3-51                   [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [32, 512, 7, 7]           [32, 512, 1, 1]           --                        --\n",
      "├─Linear: 1-10                           [32, 512]                 [32, 2]                   1,026                     True\n",
      "============================================================================================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 11,176,512\n",
      "Total mult-adds (Units.GIGABYTES): 58.03\n",
      "============================================================================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 1271.66\n",
      "Params size (MB): 44.71\n",
      "Estimated Total Size (MB): 1335.64\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(batch_size, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 15, Loss: 0.8798065930604935\n",
      "Epoch 2 / 15, Loss: 0.8848210275173187\n",
      "Epoch 3 / 15, Loss: 0.8824147954583168\n",
      "Epoch 4 / 15, Loss: 0.8799518868327141\n",
      "Epoch 5 / 15, Loss: 0.8958351314067841\n",
      "Epoch 6 / 15, Loss: 0.8909963145852089\n",
      "Epoch 7 / 15, Loss: 0.8773292377591133\n",
      "Epoch 8 / 15, Loss: 0.9258950874209404\n",
      "Epoch 9 / 15, Loss: 0.9247441440820694\n",
      "Epoch 10 / 15, Loss: 0.8841805011034012\n",
      "Epoch 11 / 15, Loss: 0.9186692908406258\n",
      "Epoch 12 / 15, Loss: 0.8964697495102882\n",
      "Epoch 13 / 15, Loss: 0.8738040551543236\n",
      "Epoch 14 / 15, Loss: 0.8921055868268013\n",
      "Epoch 15 / 15, Loss: 0.9088046252727509\n"
     ]
    }
   ],
   "source": [
    "for t in range(iterations):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        x_train, y_train = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss_val = loss(y_pred, y_train)\n",
    "        loss_history.append(loss_val.item())\n",
    "        running_loss += loss_val.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {t + 1} / {iterations}, Loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26143790849673204\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "model.eval()\n",
    "with  torch.inference_mode():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        x_test, y_test = inputs.to(device), labels.to(device)\n",
    "        y_pred = model(x_test)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        accuracy += (predicted == y_test).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {accuracy / len(testset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
